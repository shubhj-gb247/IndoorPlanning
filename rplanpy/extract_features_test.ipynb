{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rplanpy\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='batch_save.log', level=logging.INFO)\n",
    "# use all available cpu cores\n",
    "NUM_PROCESSES = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_feature_single_image(image_path):\n",
    "    try:\n",
    "        print(f\"single_image_extraction: {image_path}\\n\")\n",
    "        logging.info(f\"{image_path}\")\n",
    "        data = rplanpy.data.RplanData(image_path)\n",
    "        data.set_graph()\n",
    "        G = data.get_graph()\n",
    "\n",
    "        # print(f\"image:{image_path} \\n graph: \\n {G.graph} \\n graph.node: \\n {G.nodes.data()} \\n graph.edge: \\n {G.edges.data()} \\n \") \n",
    "        # print(\"-x-x-x--x-x-x-x-x-x-x-x--x-x-x-x\")\n",
    "\n",
    "        min_row , min_col, max_row , max_col = G.graph['site_bounding_box']\n",
    "        site_width = max_col - min_col\n",
    "        site_height = max_row - min_row\n",
    "\n",
    "        #input features\n",
    "\n",
    "        site_dim = [site_width, site_height] # list, [0] width [1] height of site. 1 per file\n",
    "\n",
    "        room_categories = []   # list , where each value means 1 room's category. 1 list per file\n",
    "        \n",
    "        #######\n",
    "\n",
    "        #target features\n",
    "\n",
    "        room_area_norm = [] # list ,each value means 1 room's area. 1 list per file\n",
    "        room_bb_norm   = [] # list of lists, where 1 list has bb of 1 room y0,x0,y1,x1. 1 per file\n",
    "        edge_list = []  # list of tuple, where one tuple will have id0,id1 => source,target for 1 edge. 1 per file\n",
    "        edge_location = [] #list of int where each value corresponds to loc of src wrt to target. mapping in rplanpy/util.py \n",
    "        edge_door = [] # list of bool , where each value tells whether door from src to target present or not\n",
    "\n",
    "\n",
    "        for node in G.nodes:\n",
    "            # get each room's category\n",
    "            room_categories.append(G.nodes[node]['category'])\n",
    "\n",
    "            # get bounding box of a room\n",
    "            r_min_row, r_min_col , r_max_row, r_max_col = G.nodes[node]['bounding_box']\n",
    "\n",
    "            x0_norm = (r_min_col - min_col) / site_width\n",
    "            y0_norm = (r_min_row - min_row) / site_height\n",
    "            x1_norm = (r_max_col - min_col) / site_width\n",
    "            y1_norm = (r_max_row - min_row) / site_height\n",
    "\n",
    "            r_area_norm = (y1_norm-y0_norm) * (x1_norm - x0_norm)\n",
    "\n",
    "            room_area_norm.append(r_area_norm)\n",
    "            room_bb_norm.append([y0_norm,x0_norm,y1_norm,x1_norm])\n",
    "\n",
    "        for src,target,edg_data in G.edges(data=True):\n",
    "            #subtracting 1 as rplan generated node id based on index 1 \n",
    "            src = src - 1\n",
    "            target = target - 1\n",
    "            location = edg_data['location']\n",
    "            door = edg_data['door']\n",
    "            edge_list.append((src,target))\n",
    "            edge_location.append(location)\n",
    "            edge_door.append(door)\n",
    "\n",
    "        print(f\"edge_list_for: {image_path} \\n{edge_list}\\n\")\n",
    "\n",
    "        input_feature_single_image = {'site_dim' : site_dim, \n",
    "                                    'room_category' : room_categories}\n",
    "        target_feature_single_image = {'room_area_norm' : room_area_norm,\n",
    "                                       'room_bb_norm'   : room_bb_norm,\n",
    "                                       'edge_list'      : edge_list,\n",
    "                                       'edge_door'      : edge_door,\n",
    "                                       'edge_location'  : edge_location}\n",
    "\n",
    "        # print(f\"image:{image_path}\\n  input: \\n : {input_feature_single_image}\\n\")\n",
    "        # print(f\"image:{image_path} \\n target: \\n {target_feature_single_image}\\n\")\n",
    "\n",
    "        return input_feature_single_image, target_feature_single_image\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"error in file: {image_path}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_image_wrapper(image_path):\n",
    "    try:\n",
    "      \n",
    "        input_feature,target_feature = prepare_feature_single_image(image_path)\n",
    "        return (input_feature,target_feature)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"error processing {image_path}: {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "\n",
    "def process_batch(image_paths, batch_index):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap(process_image_wrapper,image_paths),\n",
    "            total=len(image_paths),\n",
    "            desc = f\"Processing batch {batch_index}\"\n",
    "        ))\n",
    "\n",
    "    for input_data , target_data in results:\n",
    "        if input_data is not None and target_data is not None:\n",
    "            input_batch.append(input_data)\n",
    "            target_batch.append(target_data)\n",
    "        else:\n",
    "            logging.warning(\"Skipped an image due to processign error.\")\n",
    "        \n",
    "    if input_batch and target_batch :\n",
    "        save_batch(input_batch,target_batch,batch_index)\n",
    "        #print(f\"BATCH_INDEX: {batch_index} \\n input_batch: \\n {input_batch} \\n target_batch: \\n{target_batch}\")\n",
    "        logging.info(f\"Finished batch {batch_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_batch(input_batch, target_batch, batch_index):\n",
    "    filename = f'preprocess_data/batch_{batch_index}.h5'\n",
    "    os.makedirs('preprocess_data' ,exist_ok=True)\n",
    "\n",
    "    # filename = f'preprocess_data_temp/batch_{batch_index}.h5'\n",
    "    # os.makedirs('preprocess_data_temp' ,exist_ok=True)\n",
    "\n",
    "    with h5py.File(filename, 'w') as hf:\n",
    "        # input.1\n",
    "        site_dim = np.array([item['site_dim'] for item in input_batch], dtype=np.float32)\n",
    "        hf.create_dataset('site_dim' , data=site_dim)\n",
    "\n",
    "        # input.2\n",
    "        room_categories = [item['room_category'] for item in input_batch]\n",
    "        room_categories_lens = np.array([len(rc) for rc in room_categories], dtype=np.int32)\n",
    "        max_rc_len = room_categories_lens.max()\n",
    "\n",
    "        # padding\n",
    "        room_categories_padded = np.zeros((len(room_categories),max_rc_len),dtype=np.int32)\n",
    "        for i,rc in enumerate(room_categories):\n",
    "            room_categories_padded[i , : len(rc)] = rc\n",
    "\n",
    "        \n",
    "        # print(f\"BATCH_INDEX = {batch_index} \\nroom_categories_padded: \\n {room_categories_padded}\")\n",
    "        hf.create_dataset('room_category', data=room_categories_padded)\n",
    "        hf.create_dataset('room_category_lens', data=room_categories_lens)\n",
    "\n",
    "\n",
    "        #target.1\n",
    "        room_areas = [item['room_area_norm'] for item in target_batch]\n",
    "        room_areas_lens = np.array([len(ra) for ra in room_areas], dtype=np.int32)\n",
    "        max_ra_len = room_areas_lens.max()\n",
    "        #padding\n",
    "        room_areas_padded = np.zeros((len(room_areas), max_ra_len), dtype=np.float32)\n",
    "        for i,ra in enumerate(room_areas):\n",
    "            room_areas_padded[i, : len(ra)] = ra\n",
    "            \n",
    "        #print(f\"BATCH_INDEX = {batch_index} \\nroom_area_padded: \\n {room_areas_padded}\")\n",
    "        hf.create_dataset('room_area_norm' , data=room_areas_padded)\n",
    "        hf.create_dataset('room_area_lens' , data=room_areas_lens)\n",
    "\n",
    "        #target.2 room bb norm\n",
    "\n",
    "        room_bbs = [item['room_bb_norm'] for item in target_batch]\n",
    "        room_bbs_lens = np.array([len(bb) for bb in room_bbs],dtype=np.int32)\n",
    "        max_bb_len = room_bbs_lens.max()\n",
    "\n",
    "        room_bbs_padded = np.zeros((len(room_bbs),max_bb_len,4),dtype=np.float32)\n",
    "        for i, bb in enumerate(room_bbs):\n",
    "            room_bbs_padded[i, : len(bb)] = bb\n",
    "\n",
    "        # print(f\"BATCH_INDEX = {batch_index} \\n room_bbs_padded: \\n {room_bbs_padded}\")\n",
    "        hf.create_dataset('room_bb_norm' , data=room_bbs_padded)\n",
    "        hf.create_dataset('room_bb_norm_lens', data=room_bbs_lens)\n",
    "\n",
    "        edge_lists = [item['edge_list'] for item in target_batch]\n",
    "        edge_doors = [item['edge_door'] for item in target_batch]\n",
    "        edge_locations = [item['edge_location'] for item in target_batch]\n",
    "\n",
    "        edge_offsets = [0]\n",
    "        total_edges = sum(len(edges) for edges in edge_lists)\n",
    "        edges_src = np.zeros(total_edges,dtype=np.int32)\n",
    "        edges_tgt = np.zeros(total_edges,dtype=np.int32)\n",
    "        edges_door = np.zeros(total_edges,dtype=np.bool_)\n",
    "        edges_location = np.zeros(total_edges,dtype=np.int32)\n",
    "        idx = 0\n",
    "        for edges,doors,locations in zip(edge_lists,edge_doors,edge_locations) : \n",
    "            for (src,target) , door , loc in zip(edges,doors,locations) :\n",
    "                edges_src[idx] = src\n",
    "                edges_tgt[idx] = target\n",
    "                edges_door[idx] = door\n",
    "                edges_location[idx] = loc\n",
    "                idx += 1\n",
    "            edge_offsets.append(idx)\n",
    "\n",
    "        # print(f\"BATCH_INDEX = {batch_index} \\nedge_src: \\n {edges_src}\")\n",
    "        # print(f\"BATCH_INDEX = {batch_index} \\nedges_tgt: \\n {edges_tgt}\")\n",
    "        # print(f\"BATCH_INDEX = {batch_index} \\nedges_door: \\n {edges_door}\")\n",
    "        # print(f\"BATCH_INDEX = {batch_index} \\nedges_location: \\n {edges_location}\")\n",
    "        hf.create_dataset('edges_src', data=edges_src)\n",
    "        hf.create_dataset('edges_tgt', data=edges_tgt)\n",
    "        hf.create_dataset('edges_door', data=edges_door)\n",
    "        hf.create_dataset('edges_location', data=edges_location)\n",
    "        hf.create_dataset('edge_offsets', data=edge_offsets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_images(image_dir,batch_size):\n",
    "     \n",
    "    logging.basicConfig(filename='data_processing.log', level=logging.INFO,\n",
    "                        format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "    # Collect all image paths\n",
    "    image_paths = glob.glob(os.path.join(image_dir, '*.png'))  # Adjust the pattern as needed\n",
    "\n",
    "    total_images = len(image_paths)\n",
    "    total_batches = (total_images + batch_size - 1) // batch_size\n",
    "\n",
    "    logging.info(f\"Starting processing of {total_images} images in {total_batches} batches.\")\n",
    "    for batch_index in range(total_batches):\n",
    "        start_idx = batch_index * batch_size\n",
    "        end_idx = min(start_idx + batch_size, total_images)\n",
    "        batch_image_paths = image_paths[start_idx:end_idx]\n",
    "        logging.info(f\"Processing batch {batch_index + 1}/{total_batches} with {len(batch_image_paths)} images.\")\n",
    "        process_batch(batch_image_paths, batch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../dataset/floorplan_dataset'\n",
    "#IMAGE_DIR =  './floorplan_dataset_temp'\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "\n",
    "\n",
    "process_all_images(IMAGE_DIR,BATCH_SIZE)\n",
    "logging.info(\"-x-x-x-x-x-x-Finished-x-x-x-x-x-x-x-x-x\")\n",
    "print(\"-x-x-x-x-x-x-xx-Finished-x-x--x-x--x-x-x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
